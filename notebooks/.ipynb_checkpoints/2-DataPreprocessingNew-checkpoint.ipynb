{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import re\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "import zipfile\n",
    "import lzma\n",
    "from os.path import isfile, join\n",
    "from random import sample \n",
    "import ast\n",
    "# directory = os.chdir(r'C:\\Users\\Leonardo\\OneDrive\\Documents\\TU_Delft\\CodingProjects\\PoliceBrutality\\data\\raw\\test')\n",
    "directory = os.chdir(r'E:\\PoliceBrutality\\data\\raw\\0529_0607')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method with Json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = [file for file in os.listdir(directory) if file.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_files_sp = [file for day in days for file in files if file.startswith(day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take a 100 sample of each day\n",
    "# for day in days:\n",
    "#     exec(f'list_files_sp_{day} = sample([file for file in files if file.startswith(day)], 100)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take a 10% sample of each day\n",
    "# days = [\"0529\", '0530', '0531', '0601']\n",
    "\n",
    "# frac = 0.1\n",
    "# samples = []\n",
    "# for day in days:\n",
    "#     exec('l = [file for file in list_files if file.startswith(day)]')\n",
    "#     exec(f'list_files_sp_{day} = sample(l, int(frac*len(l)))')\n",
    "#     exec(f'samples.append(list_files_sp_{day})')\n",
    "    \n",
    "# list_files = [item for sublist in samples for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(directory) if file.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a 10% sample of each day\n",
    "days = list(set([file[:4] for file in files]))\n",
    "\n",
    "frac = 0.01\n",
    "samples = []\n",
    "for day in days:\n",
    "    l = [file for file in files if file.startswith(day)]\n",
    "\n",
    "    l_sample = sample(l, int(frac*len(l)))\n",
    "\n",
    "    samples.append(l_sample)\n",
    "    \n",
    "list_files = [item for sublist in samples for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4078"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4078"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples[0]) + len(samples[1]) + len(samples[2]) + len(samples[3]) + len(samples[4]) + len(samples[5]) + len(samples[6]) + len(samples[7]) + len(samples[8]) + len(samples[9]) + len(samples[10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# import re\n",
    "# p = re.compile('(?<!\\\\\\\\)\\'')\n",
    "# tweet_files = [json.loads(json.dumps(line)) for file in list_files[0:2] for line in open(file, 'r')]\n",
    "tweet_files = [json.loads(line) for file in list_files for line in open(file, 'r')]\n",
    "tweets = [tweet for tweet_file in tweet_files for tweet in tweet_file]\n",
    "print(\"Loaded a sample of\", len(tweet_files), \"files and\", len(tweets), \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a sample of 4070 files and 407000 tweets\n"
     ]
    }
   ],
   "source": [
    "# tweet_files\n",
    "# tweet_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def clean_tweets(tweet):\n",
    " \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    #after tweepy preprocessing the colon symbol left remain after      #removing mentions\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "    #remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "    #filter using NLTK library append it to a string\n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "    #looping through conditions\n",
    "    for w in word_tokens:\n",
    "    #check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)\n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)return tweet\n",
    "    \n",
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    "\n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)\n",
    "\n",
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "    \n",
    "cols = ['tweet_id', 'created_at', 'source', 'text','full_text','clean_text', 'is_retweet', 'sentiment','polarity', 'subjectivity','language', \n",
    "        'coordinates', 'geolocation', 'place_full_name','place_country_code','place_country','place_type','place_bbox', 'user_location', 'user', 'user_friends', \n",
    "        'user_followers', 'original_author', 'hashtags', 'retweet_count', 'favorite_count']\n",
    "\n",
    "tweet_id = []\n",
    "created_at = []\n",
    "source = []\n",
    "text = []\n",
    "full_text = []\n",
    "clean_text = []\n",
    "is_retweet = []\n",
    "sentiment = []\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "lang = []\n",
    "coordinates = []\n",
    "geolocation = []\n",
    "# place = []\n",
    "place_full_name = []\n",
    "place_country_code = []\n",
    "place_country = []\n",
    "place_type = []\n",
    "place_bbox = []\n",
    "user_location = []\n",
    "user = []\n",
    "user_friends = []\n",
    "user_followers = []\n",
    "original_author = []\n",
    "hashtags = []\n",
    "hashtag_list = []\n",
    "retweet_count = []\n",
    "favorite_count = []\n",
    "\n",
    "# create list with all of the json files\n",
    "# list_files = [file for file in os.listdir(directory) if file.endswith('.json')]\n",
    "\n",
    "# tweet_files = [json.loads(line) for file in list_files for line in open(file, 'r')]\n",
    "\n",
    "# tweets = [tweet for tweet_file in tweet_files for tweet in tweet_file]\n",
    "\n",
    "for tweet in range(0, len(tweets)):\n",
    "    # get id\n",
    "    if 'text' in tweets[tweet].keys():\n",
    "        # get id\n",
    "        tweet_id.append(tweets[tweet]['id'])\n",
    "        # get source\n",
    "        source.append(tweets[tweet]['source'])\n",
    "        # get day-time\n",
    "        created_at.append(tweets[tweet]['created_at'])\n",
    "        # get original_text\n",
    "        text.append(tweets[tweet]['text'])\n",
    "        # get language\n",
    "        lang.append(tweets[tweet]['lang'])\n",
    "        # get user screen_name\n",
    "        user.append(tweets[tweet]['user']['screen_name'])\n",
    "        # get user friends\n",
    "        user_friends.append(tweets[tweet]['user']['friends_count'])\n",
    "        # get user followers\n",
    "        user_followers.append(tweets[tweet]['user']['followers_count'])\n",
    "\n",
    "        # get tweet coordinates\n",
    "        try:\n",
    "            coord = tweets[tweet]['coordinates']  \n",
    "        except TypeError:\n",
    "            coord = np.NaN\n",
    "        coordinates.append(coord)\n",
    "\n",
    "        # geo attribute\n",
    "        try:\n",
    "            geo = tweets[tweet]['geo']  \n",
    "        except TypeError:\n",
    "            geo = np.NaN\n",
    "        geolocation.append(geo)\n",
    "\n",
    "        # get tweet place full name\n",
    "        try:\n",
    "            full_name = tweets[tweet]['place']['full_name']\n",
    "        except TypeError:\n",
    "            full_name = np.NaN\n",
    "        place_full_name.append(full_name)\n",
    "        # get tweet place country code\n",
    "        try:\n",
    "            country_code = tweets[tweet]['place']['country_code']\n",
    "        except TypeError:\n",
    "            country_code = np.NaN\n",
    "        place_country_code.append(country_code)\n",
    "        # get tweet place country\n",
    "        try:\n",
    "            country = tweets[tweet]['place']['country']\n",
    "        except TypeError:\n",
    "            country = np.NaN\n",
    "        place_country.append(country)\n",
    "        # get tweet place type\n",
    "        try:\n",
    "            ptype = tweets[tweet]['place']['place_type']\n",
    "        except TypeError:\n",
    "            ptype = np.NaN\n",
    "        place_type.append(ptype)\n",
    "        # get tweet place bounding box\n",
    "        try:\n",
    "            bbox = tweets[tweet]['place']['bounding_box']['coordinates']\n",
    "        except TypeError:\n",
    "            bbox = np.NaN\n",
    "        place_bbox.append(bbox)\n",
    "\n",
    "        # get user location\n",
    "        try:\n",
    "            user_location.append(tweets[tweet]['user']['location'])\n",
    "        except TypeError:\n",
    "            user_location.append(np.NaN)\n",
    "\n",
    "    # Retweet specific attributes:\n",
    "#             if list(pd.Series(tweets[0][tweet]['text']).str.contains('RT '))[0] == False:\n",
    "        if list(pd.Series(tweets[tweet]['text']).str.contains('RT '))[0] == False & tweets[tweet]['is_quote_status'] == False:\n",
    "            ## get full text\n",
    "            try:\n",
    "                full_text.append(tweets[tweet]['extended_tweet']['full_text'])\n",
    "            except KeyError:\n",
    "                full_text.append(tweets[tweet]['text'])\n",
    "            ## get hashtags\n",
    "            hashtags.append(tweets[tweet]['entities']['hashtags'])\n",
    "            ## get retweet count\n",
    "            retweet_count.append(tweets[tweet]['retweet_count'])\n",
    "            ## get favorite count\n",
    "            favorite_count.append(tweets[tweet]['favorite_count'])\n",
    "            ## original author\n",
    "            original_author.append(tweets[tweet]['user']['screen_name'])\n",
    "            ## retweeted status\n",
    "            is_retweet.append(False)\n",
    "            ## quoted status\n",
    "#                 is_quote.append(False)\n",
    "        ## get full text from extended tweet        \n",
    "        else:\n",
    "            ## retweeted status\n",
    "            is_retweet.append(True)\n",
    "\n",
    "            try:\n",
    "                full_text.append(tweets[tweet]['retweeted_status']['extended_tweet']['full_text'])\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    full_text.append(tweets[tweet]['retweeted_status']['quoted_status']['extended_tweet']['full_text'])\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        full_text.append(tweets[tweet]['quoted_status']['extended_tweet']['full_text'])\n",
    "                    except KeyError:\n",
    "                        try:\n",
    "                            full_text.append(tweets[tweet]['retweeted_status']['text'])\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "\n",
    "            ## get retweet count and favorite count for retweeted tweets\n",
    "            try:\n",
    "                retweet_count.append(tweets[tweet]['retweeted_status']['retweet_count'])\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    retweet_count.append(tweets[tweet]['quoted_status']['retweet_count'])\n",
    "                except KeyError:\n",
    "                    retweet_count.append(np.NaN)\n",
    "            # favorites count\n",
    "            try:\n",
    "                favorite_count.append(tweets[tweet]['retweeted_status']['favorite_count'])\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    favorite_count.append(tweets[tweet]['quoted_status']['favorite_count'])\n",
    "                except KeyError:\n",
    "                    favorite_count.append(np.NaN)\n",
    "            ## get original hashtags\n",
    "            try:\n",
    "                hashtags.append(tweets[tweet]['retweeted_status']['extended_tweet']['entities']['hashtags'])\n",
    "            except KeyError:\n",
    "                try:\n",
    "                    hashtags.append(tweets[tweet]['retweeted_status']['quoted_status']['extended_tweet']['entities']['hashtags'])\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        hashtags.append(tweets[tweet]['quoted_status']['extended_tweet']['entities']['hashtags'])\n",
    "                    except KeyError:\n",
    "                        try:\n",
    "                            hashtags.append(tweets[tweet]['retweeted_status']['entities']['hashtags'])\n",
    "                        except KeyError:\n",
    "                            hashtags.append(np.NaN)\n",
    "            # get original author\n",
    "            try:\n",
    "                original_author.append(tweets[tweet]['text'].split(\" \",2)[1].replace('@', '').replace(':', ''))\n",
    "            except TypeError:\n",
    "                try:\n",
    "                    original_author.append(tweets[tweet]['quoted_status']['user']['screen_name'])\n",
    "                except KeyError:\n",
    "                    original_author.append(np.NaN)\n",
    "# clean hashtags                    \n",
    "for words in hashtags:\n",
    "    try:\n",
    "        ds = words\n",
    "        d = {}\n",
    "        for k in ds[0].keys():\n",
    "            d[k] = tuple(d[k] for d in ds)\n",
    "        hashtag_list.append(list(d['text']))\n",
    "    except (IndexError, TypeError) as e:\n",
    "        hashtag_list.append(np.NaN)\n",
    "        \n",
    "# clean text and tokenize tweets\n",
    "for t in full_text:\n",
    "    clean_text.append(clean_tweets(p.clean(t)))\n",
    "\n",
    "# sentiment analysis\n",
    "for clean_tweet in clean_text:\n",
    "    blob = TextBlob(clean_tweet)\n",
    "#     sentiment = blob.sentiment\n",
    "    sentiment.append(blob.sentiment)\n",
    "    polarity.append(blob.sentiment.polarity)\n",
    "    subjectivity.append(blob.sentiment.subjectivity)\n",
    "                            \n",
    "tweets_df = pd.DataFrame(list(zip(tweet_id, created_at, source, text, full_text, clean_text, is_retweet, sentiment,polarity, subjectivity, lang, \n",
    "                                  coordinates, geolocation, place_full_name,place_country_code,place_country,place_type,place_bbox, user_location, \n",
    "                                  user, user_friends, user_followers, original_author, hashtag_list, retweet_count, favorite_count)), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# def clean_tweets(tweet):\n",
    " \n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     word_tokens = word_tokenize(tweet)\n",
    "#     #after tweepy preprocessing the colon symbol left remain after      #removing mentions\n",
    "#     tweet = re.sub(r':', '', tweet)\n",
    "#     tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "#     #replace consecutive non-ASCII characters with a space\n",
    "#     tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "#     #remove emojis from tweet\n",
    "#     tweet = emoji_pattern.sub(r'', tweet)\n",
    "#     #filter using NLTK library append it to a string\n",
    "#     filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "#     filtered_tweet = []\n",
    "#     #looping through conditions\n",
    "#     for w in word_tokens:\n",
    "#     #check tokens against stop words , emoticons and punctuations\n",
    "#         if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "#             filtered_tweet.append(w)\n",
    "#     return ' '.join(filtered_tweet)\n",
    "#     #print(word_tokens)\n",
    "#     #print(filtered_sentence)return tweet\n",
    "    \n",
    "# #HappyEmoticons\n",
    "# emoticons_happy = set([\n",
    "#     ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "#     ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "#     '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "#     'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "#     '<3'\n",
    "#     ])\n",
    "\n",
    "# # Sad Emoticons\n",
    "# emoticons_sad = set([\n",
    "#     ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "#     ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "#     ':c', ':{', '>:\\\\', ';('\n",
    "#     ])\n",
    "\n",
    "# #Emoji patterns\n",
    "# emoji_pattern = re.compile(\"[\"\n",
    "#          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#          u\"\\U00002702-\\U000027B0\"\n",
    "#          u\"\\U000024C2-\\U0001F251\"\n",
    "#          \"]+\", flags=re.UNICODE)\n",
    "\n",
    "# #combine sad and happy emoticons\n",
    "# emoticons = emoticons_happy.union(emoticons_sad)\n",
    "    \n",
    "# cols = ['id', 'created_at', 'source', 'text','full_text','clean_text', 'is_retweet', 'sentiment','polarity', 'subjectivity','language', \n",
    "#         'coordinates', 'geolocation', 'place_full_name','place_country_code','place_country','place_type','place_bbox', 'user_location', 'user', 'user_friends', \n",
    "#         'user_followers', 'original_author', 'hashtags', 'retweet_count', 'favorite_count']\n",
    "\n",
    "# id = []\n",
    "# created_at = []\n",
    "# source = []\n",
    "# text = []\n",
    "# full_text = []\n",
    "# clean_text = []\n",
    "# is_retweet = []\n",
    "# sentiment = []\n",
    "# polarity = []\n",
    "# subjectivity = []\n",
    "# lang = []\n",
    "# coordinates = []\n",
    "# geolocation = []\n",
    "# # place = []\n",
    "# place_full_name = []\n",
    "# place_country_code = []\n",
    "# place_country = []\n",
    "# place_type = []\n",
    "# place_bbox = []\n",
    "# user_location = []\n",
    "# user = []\n",
    "# user_friends = []\n",
    "# user_followers = []\n",
    "# original_author = []\n",
    "# hashtags = []\n",
    "# hashtag_list = []\n",
    "# retweet_count = []\n",
    "# favorite_count = []\n",
    "\n",
    "# # create list with all of the json files\n",
    "# list_files = [file for file in os.listdir(directory) if file.endswith('.json')]\n",
    "\n",
    "# tweets = [json.loads(line) for file in list_files for line in open(file, 'r')]\n",
    "\n",
    "# for tweet_file in range(0,len(tweets)):\n",
    "\n",
    "#     for tweet in range(0, len(tweets[tweet_file])):\n",
    "#         # get id\n",
    "#         if 'text' in tweets[0][tweet].keys():\n",
    "#             # get id\n",
    "#             id.append(tweets[0][tweet]['id'])\n",
    "#             # get source\n",
    "#             source.append(tweets[0][tweet]['source'])\n",
    "#             # get day-time\n",
    "#             created_at.append(tweets[0][tweet]['created_at'])\n",
    "#             # get original_text\n",
    "#             text.append(tweets[0][tweet]['text'])\n",
    "#             # get language\n",
    "#             lang.append(tweets[0][tweet]['lang'])\n",
    "#             # get user screen_name\n",
    "#             user.append(tweets[0][tweet]['user']['screen_name'])\n",
    "#             # get user friends\n",
    "#             user_friends.append(tweets[0][tweet]['user']['friends_count'])\n",
    "#             # get user followers\n",
    "#             user_followers.append(tweets[0][tweet]['user']['followers_count'])\n",
    "            \n",
    "#             # get tweet coordinates\n",
    "#             try:\n",
    "#                 coord = tweets[0][tweet]['coordinates']  \n",
    "#             except TypeError:\n",
    "#                 coord = np.NaN\n",
    "#             coordinates.append(coord)\n",
    "            \n",
    "#             # geo attribute\n",
    "#             try:\n",
    "#                 geo = tweets[0][tweet]['geo']  \n",
    "#             except TypeError:\n",
    "#                 geo = np.NaN\n",
    "#             geolocation.append(geo)\n",
    "                \n",
    "#             # get tweet place full name\n",
    "#             try:\n",
    "#                 full_name = tweets[0][tweet]['place']['full_name']\n",
    "#             except TypeError:\n",
    "#                 full_name = np.NaN\n",
    "#             place_full_name.append(full_name)\n",
    "#             # get tweet place country code\n",
    "#             try:\n",
    "#                 country_code = tweets[0][tweet]['place']['country_code']\n",
    "#             except TypeError:\n",
    "#                 country_code = np.NaN\n",
    "#             place_country_code.append(country_code)\n",
    "#             # get tweet place country\n",
    "#             try:\n",
    "#                 country = tweets[0][tweet]['place']['country']\n",
    "#             except TypeError:\n",
    "#                 country = np.NaN\n",
    "#             place_country.append(country)\n",
    "#             # get tweet place type\n",
    "#             try:\n",
    "#                 ptype = tweets[0][tweet]['place']['place_type']\n",
    "#             except TypeError:\n",
    "#                 ptype = np.NaN\n",
    "#             place_type.append(ptype)\n",
    "#             # get tweet place bounding box\n",
    "#             try:\n",
    "#                 bbox = tweets[0][tweet]['place']['bounding_box']['coordinates']\n",
    "#             except TypeError:\n",
    "#                 bbox = np.NaN\n",
    "#             place_bbox.append(bbox)\n",
    "\n",
    "#             # get user location\n",
    "#             try:\n",
    "#                 user_location.append(tweets[0][tweet]['user']['location'])\n",
    "#             except TypeError:\n",
    "#                 user_location.append(np.NaN)\n",
    "\n",
    "#         # Retweet specific attributes:\n",
    "# #             if list(pd.Series(tweets[0][tweet]['text']).str.contains('RT '))[0] == False:\n",
    "#             if list(pd.Series(tweets[0][tweet]['text']).str.contains('RT '))[0] == False & tweets[0][tweet]['is_quote_status'] == False:\n",
    "#                 ## get full text\n",
    "#                 try:\n",
    "#                     full_text.append(tweets[0][tweet]['extended_tweet']['full_text'])\n",
    "#                 except KeyError:\n",
    "#                     full_text.append(tweets[0][tweet]['text'])\n",
    "#                 ## get hashtags\n",
    "#                 hashtags.append(tweets[0][tweet]['entities']['hashtags'])\n",
    "#                 ## get retweet count\n",
    "#                 retweet_count.append(tweets[0][tweet]['retweet_count'])\n",
    "#                 ## get favorite count\n",
    "#                 favorite_count.append(tweets[0][tweet]['favorite_count'])\n",
    "#                 ## original author\n",
    "#                 original_author.append(tweets[0][tweet]['user']['screen_name'])\n",
    "#                 ## retweeted status\n",
    "#                 is_retweet.append(False)\n",
    "#                 ## quoted status\n",
    "# #                 is_quote.append(False)\n",
    "#             ## get full text from extended tweet        \n",
    "#             else:\n",
    "#                 ## retweeted status\n",
    "#                 is_retweet.append(True)\n",
    "                \n",
    "#                 try:\n",
    "#                     full_text.append(tweets[0][tweet]['retweeted_status']['extended_tweet']['full_text'])\n",
    "#                 except KeyError:\n",
    "#                     try:\n",
    "#                         full_text.append(tweets[0][tweet]['retweeted_status']['quoted_status']['extended_tweet']['full_text'])\n",
    "#                     except KeyError:\n",
    "#                         try:\n",
    "#                             full_text.append(tweets[0][tweet]['quoted_status']['extended_tweet']['full_text'])\n",
    "#                         except KeyError:\n",
    "#                             try:\n",
    "#                                 full_text.append(tweets[0][tweet]['retweeted_status']['text'])\n",
    "#                             except KeyError:\n",
    "#                                 pass\n",
    "                            \n",
    "#                 ## get retweet count and favorite count for retweeted tweets\n",
    "#                 try:\n",
    "#                     retweet_count.append(tweets[0][tweet]['retweeted_status']['retweet_count'])\n",
    "#                     favorite_count.append(tweets[0][tweet]['retweeted_status']['favorite_count'])\n",
    "#                 except KeyError:\n",
    "#                     retweet_count.append(tweets[0][tweet]['quoted_status']['retweet_count'])\n",
    "#                     favorite_count.append(tweets[0][tweet]['quoted_status']['favorite_count'])\n",
    "#                 ## get original hashtags\n",
    "#                 try:\n",
    "#                     hashtags.append(tweets[0][tweet]['retweeted_status']['extended_tweet']['entities']['hashtags'])\n",
    "#                 except KeyError:\n",
    "#                     try:\n",
    "#                         hashtags.append(tweets[0][tweet]['retweeted_status']['quoted_status']['extended_tweet']['entities']['hashtags'])\n",
    "#                     except KeyError:\n",
    "#                         try:\n",
    "#                             hashtags.append(tweets[0][tweet]['quoted_status']['extended_tweet']['entities']['hashtags'])\n",
    "#                         except KeyError:\n",
    "#                             try:\n",
    "#                                 hashtags.append(tweets[0][tweet]['retweeted_status']['entities']['hashtags'])\n",
    "#                             except KeyError:\n",
    "#                                 hashtags.append(np.NaN)\n",
    "#                 # get original author\n",
    "#                 try:\n",
    "#                     original_author.append(tweets[0][tweet]['text'].split(\" \",2)[1].replace('@', '').replace(':', ''))\n",
    "#                 except TypeError:\n",
    "#                     try:\n",
    "#                         original_author.append(tweets[0][tweet]['quoted_status']['user']['screen_name'])\n",
    "#                     except KeyError:\n",
    "#                         original_author.append(np.NaN)\n",
    "# # clean hashtags                    \n",
    "# for words in hashtags:\n",
    "#     try:\n",
    "#         ds = words\n",
    "#         d = {}\n",
    "#         for k in ds[0].keys():\n",
    "#             d[k] = tuple(d[k] for d in ds)\n",
    "#         hashtag_list.append(list(d['text']))\n",
    "#     except IndexError:\n",
    "#         hashtag_list.append(np.NaN)\n",
    "        \n",
    "# # clean text and tokenize tweets\n",
    "# for t in full_text:\n",
    "#     clean_text.append(clean_tweets(p.clean(t)))\n",
    "\n",
    "# # sentiment analysis\n",
    "# for clean_tweet in clean_text:\n",
    "#     blob = TextBlob(clean_tweet)\n",
    "# #     sentiment = blob.sentiment\n",
    "#     sentiment.append(blob.sentiment)\n",
    "#     polarity.append(blob.sentiment.polarity)\n",
    "#     subjectivity.append(blob.sentiment.subjectivity)\n",
    "                            \n",
    "# tweets_df = pd.DataFrame(list(zip(id, created_at, source, text, full_text, clean_text, is_retweet, sentiment,polarity, subjectivity, lang, \n",
    "#                                   coordinates, geolocation, place_full_name,place_country_code,place_country,place_type,place_bbox, user_location, \n",
    "#                                   user, user_friends, user_followers, original_author, hashtag_list, retweet_count, favorite_count)), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write files\n",
    "tweets_df.to_csv(f'../interim/sample_{sorted(days[0])}_{sorted(days[-1])}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#load files\n",
    "tweets_df1 = pd.read_csv('../sample.csv')\n",
    "tweets_df2 = pd.read_csv('../sample2.csv')\n",
    "tweets_df3 = pd.read_csv('../sample3.csv')\n",
    "tweets_df4 = pd.read_csv('../sample4.csv')\n",
    "tweets_df5 = pd.read_csv('../sample5.csv')\n",
    "#merge tweets together\n",
    "dfs = [tweets_df1, tweets_df2, tweets_df3, tweets_df4, tweets_df5]\n",
    "tweets_df = pd.concat(dfs).sort_values('created_at').reset_index().drop(['Unnamed: 0', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2066655 and 2065577 unique Tweets, from Tue Jun 23 03:25:08 +0000 2020 to Tue Jun 23 23:01:31 +0000 2020\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(tweets_df['tweet_id']), \"and\", len(tweets_df['tweet_id'].unique()), \"unique Tweets, from\", \n",
    "      tweets_df.sort_values('created_at')['created_at'][0], \"to\", tweets_df.sort_values('created_at')['created_at'][len(tweets_df)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of geolocated tweets is 0.02472594603356632 %:  511 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"The percentage of geolocated tweets is\", len(tweets_df['coordinates'][tweets_df['coordinates'].isna()==False])/len(tweets_df)*100, \"%: \", \n",
    "      len(tweets_df['coordinates'][tweets_df['coordinates'].isna()==False]), \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of tweets with place is 0.5072447989625748 %:  10483 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"The percentage of tweets with place is\", len(tweets_df['place_full_name'][tweets_df['place_full_name'].isna()==False])/len(tweets_df)*100, \"%: \", \n",
    "      len(tweets_df['place_full_name'][tweets_df['place_full_name'].isna()==False]), \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of tweets with user location is 63.79284399186125 %:  1318439 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"The percentage of tweets with user location is\", len(tweets_df['user_location'][(tweets_df['user_location'].astype('str') !='None')&\n",
    "                                                                                       (tweets_df['user_location'].isna()==False)])/len(tweets_df)*100, \"%: \", \n",
    "      len(tweets_df['user_location'][tweets_df['user_location'].isna()==False]), \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of tweets vs. retweets is 25.35384861738979 %\n"
     ]
    }
   ],
   "source": [
    "print(\"The percentage of tweets vs. retweets is\", len(tweets_df[tweets_df['is_retweet']==False])/len(tweets_df[tweets_df['is_retweet']==True])*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "def clean_tweets(tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\") \n",
    "    \n",
    "    #remove twitter handles (@xxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"@[\\w]*\")\n",
    "    \n",
    "    #remove URL links (httpxxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "\n",
    "    #remove special characters, numbers, punctuations (except for #)\n",
    "    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "tweets_df['clean_text']= clean_tweets(tweets_df['clean_text'].astype('str')) #The function clean_tweets were put to use.\n",
    "# tweets_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#importing and initialising the VADER analyser\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Storing the scores in list of dictionaries\n",
    "scores = []\n",
    "# Declare variables for scores\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "for i in range(tweets_df['clean_text'].shape[0]):\n",
    "#print(analyser.polarity_scores(sentiments_pd['Tweet'][i]))\n",
    "    compound = analyzer.polarity_scores(tweets_df['clean_text'][i])[\"compound\"]\n",
    "    pos = analyzer.polarity_scores(tweets_df['clean_text'][i])[\"pos\"]\n",
    "    neu = analyzer.polarity_scores(tweets_df['clean_text'][i])[\"neu\"]\n",
    "    neg = analyzer.polarity_scores(tweets_df['clean_text'][i])[\"neg\"]\n",
    "    \n",
    "    scores.append({\"compound_s\": compound,\n",
    "                       \"positive_s\": pos,\n",
    "                       \"negative_s\": neg,\n",
    "                       \"neutral_s\": neu\n",
    "                  })\n",
    "\n",
    "#Appending the scores into the dataframe for further analysis \n",
    "sentiments_score = pd.DataFrame.from_dict(scores)\n",
    "tweets_df_sent = tweets_df.join(sentiments_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df_sent.to_csv('../2Mtweets_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import vaex\n",
    "# tweets_df_sent = vaex.open('../2Mtweets_sentiment.csv')\n",
    "tweets_df_sent = pd.read_csv('../2Mtweets_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>...</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>original_author</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>compound_s</th>\n",
       "      <th>positive_s</th>\n",
       "      <th>negative_s</th>\n",
       "      <th>neutral_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1275268627676217345</td>\n",
       "      <td>Tue Jun 23 03:25:08 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @DangeRussWilson: The only thing that must ...</td>\n",
       "      <td>The only thing that must die... is \\nRACISM.</td>\n",
       "      <td>The thing must die ... RACISM</td>\n",
       "      <td>True</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>341</td>\n",
       "      <td>DangeRussWilson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10540.0</td>\n",
       "      <td>65764.0</td>\n",
       "      <td>-0.8668</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1275268628225679361</td>\n",
       "      <td>Tue Jun 23 03:25:08 +0000 2020</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>RT @CIAspygirl: Kayleigh McEnany is only 32. A...</td>\n",
       "      <td>Kayleigh McEnany is only 32. And no matter wha...</td>\n",
       "      <td>Kayleigh McEnany And matter accomplishes lifet...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1322</td>\n",
       "      <td>280</td>\n",
       "      <td>CIAspygirl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2844.0</td>\n",
       "      <td>11045.0</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1275268628305281025</td>\n",
       "      <td>Tue Jun 23 03:25:08 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>RT @TheLeoTerrell: Attention Black Lives Matte...</td>\n",
       "      <td>Attention Black Lives Matter. During Father Da...</td>\n",
       "      <td>Attention Black Lives Matter During Father Day...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sentiment(polarity=-0.12777777777777777, subje...</td>\n",
       "      <td>-0.127778</td>\n",
       "      <td>...</td>\n",
       "      <td>2614</td>\n",
       "      <td>1699</td>\n",
       "      <td>TheLeoTerrell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10960.0</td>\n",
       "      <td>18739.0</td>\n",
       "      <td>-0.8860</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1275268628116619266</td>\n",
       "      <td>Tue Jun 23 03:25:08 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @letarik_b: THIS BLACK BOY WHO PLAYED THE V...</td>\n",
       "      <td>THIS BLACK BOY WHO PLAYED THE VIOLIN FOR KITTE...</td>\n",
       "      <td>THIS BLACK BOY WHO PLAYED THE VIOLIN FOR KITTE...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sentiment(polarity=-0.18888888888888888, subje...</td>\n",
       "      <td>-0.188889</td>\n",
       "      <td>...</td>\n",
       "      <td>219</td>\n",
       "      <td>74</td>\n",
       "      <td>letarik_b</td>\n",
       "      <td>['ElijahMcClain']</td>\n",
       "      <td>191498.0</td>\n",
       "      <td>270442.0</td>\n",
       "      <td>-0.7526</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1275268627667628033</td>\n",
       "      <td>Tue Jun 23 03:25:08 +0000 2020</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @ciarralifts: In case you haven’t heard it ...</td>\n",
       "      <td>In case you haven’t heard it yet today, black ...</td>\n",
       "      <td>In case havent heard yet today black lives fuc...</td>\n",
       "      <td>True</td>\n",
       "      <td>Sentiment(polarity=-0.3833333333333333, subjec...</td>\n",
       "      <td>-0.383333</td>\n",
       "      <td>...</td>\n",
       "      <td>685</td>\n",
       "      <td>575</td>\n",
       "      <td>ciarralifts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             tweet_id                      created_at  \\\n",
       "0           0  1275268627676217345  Tue Jun 23 03:25:08 +0000 2020   \n",
       "1           1  1275268628225679361  Tue Jun 23 03:25:08 +0000 2020   \n",
       "2           2  1275268628305281025  Tue Jun 23 03:25:08 +0000 2020   \n",
       "3           3  1275268628116619266  Tue Jun 23 03:25:08 +0000 2020   \n",
       "4           4  1275268627667628033  Tue Jun 23 03:25:08 +0000 2020   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @DangeRussWilson: The only thing that must ...   \n",
       "1  RT @CIAspygirl: Kayleigh McEnany is only 32. A...   \n",
       "2  RT @TheLeoTerrell: Attention Black Lives Matte...   \n",
       "3  RT @letarik_b: THIS BLACK BOY WHO PLAYED THE V...   \n",
       "4  RT @ciarralifts: In case you haven’t heard it ...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0       The only thing that must die... is \\nRACISM.   \n",
       "1  Kayleigh McEnany is only 32. And no matter wha...   \n",
       "2  Attention Black Lives Matter. During Father Da...   \n",
       "3  THIS BLACK BOY WHO PLAYED THE VIOLIN FOR KITTE...   \n",
       "4  In case you haven’t heard it yet today, black ...   \n",
       "\n",
       "                                          clean_text  is_retweet  \\\n",
       "0                      The thing must die ... RACISM        True   \n",
       "1  Kayleigh McEnany And matter accomplishes lifet...        True   \n",
       "2  Attention Black Lives Matter During Father Day...        True   \n",
       "3  THIS BLACK BOY WHO PLAYED THE VIOLIN FOR KITTE...        True   \n",
       "4  In case havent heard yet today black lives fuc...        True   \n",
       "\n",
       "                                           sentiment  polarity  ...  \\\n",
       "0          Sentiment(polarity=0.0, subjectivity=0.0)  0.000000  ...   \n",
       "1          Sentiment(polarity=0.0, subjectivity=0.0)  0.000000  ...   \n",
       "2  Sentiment(polarity=-0.12777777777777777, subje... -0.127778  ...   \n",
       "3  Sentiment(polarity=-0.18888888888888888, subje... -0.188889  ...   \n",
       "4  Sentiment(polarity=-0.3833333333333333, subjec... -0.383333  ...   \n",
       "\n",
       "   user_friends user_followers  original_author           hashtags  \\\n",
       "0           209            341  DangeRussWilson                NaN   \n",
       "1          1322            280       CIAspygirl                NaN   \n",
       "2          2614           1699    TheLeoTerrell                NaN   \n",
       "3           219             74        letarik_b  ['ElijahMcClain']   \n",
       "4           685            575      ciarralifts                NaN   \n",
       "\n",
       "  retweet_count favorite_count compound_s positive_s negative_s neutral_s  \n",
       "0       10540.0        65764.0    -0.8668      0.000      0.686     0.314  \n",
       "1        2844.0        11045.0    -0.7430      0.174      0.370     0.457  \n",
       "2       10960.0        18739.0    -0.8860      0.108      0.318     0.575  \n",
       "3      191498.0       270442.0    -0.7526      0.109      0.195     0.696  \n",
       "4          33.0           82.0     0.1010      0.134      0.000     0.866  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_sent.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Compound Sentiment')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "plt.hist(tweets_df_sent['compound_s'].values, bins=40)\n",
    "plt.title('Histogram of Compound Sentiment')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.xlabel('Compound Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "from wordcloud import ImageColorGenerator\n",
    "# import image\n",
    "# char_mask = np.array(Image.open(\"IMAGE_FILE.jpg\"))\n",
    "# image_colors = ImageColorGenerator(char_mask) # to recolor the word cloud to represent the colours from the image\n",
    "# generate wordcloud\n",
    "print('Generating word cloud....')\n",
    "# wc = WordCloud(background_color=\"black\", max_words=700, width=1600, height=800,\n",
    "# mask=char_mask, random_state=1).generate(' '.join(df['Tweet'])) #max_words must be less than number of unique words in your data\n",
    "\n",
    "wc = WordCloud(background_color=\"black\", max_words=700, width=1600, height=800, random_state=1).generate(' '.join(tweets_df_sent['clean_text']))\n",
    "    \n",
    "print('Making plot')\n",
    "plt.figure(figsize=(20,10))\n",
    "ypos = 800\n",
    "plt.style.use('dark_background')\n",
    "plt.imshow(wc) #Shows the word cloud\n",
    "plt.axis(\"off\") \n",
    "# plt.savefig('blm.png') #to save the figure into your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(tweets_df_sent['full_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Retweets')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_bins= 30\n",
    "plt.hist(tweets_df['retweet_count'][tweets_df['retweet_count']<100000], n_bins, histtype='step', stacked=True, fill = True)\n",
    "plt.title('Histogram of Retweets')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.xlabel('Retweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.plot(tweets_df['created_at'], tweets_df['polarity'])\n",
    "plt.title('Tweet polarity over the course of one day (june 23rd)')\n",
    "plt.ylabel('Polarity')\n",
    "plt.xlabel('Time of Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji --upgrade\n",
    "# !pip install pandas-profiling==2.*\n",
    "# !pip install plotly==4.*\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_lg\n",
    "!pip install pyldavis\n",
    "!pip install gensim\n",
    "# !pip install chart_studio\n",
    "!pip install --upgrade autopep8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leonardo\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#Base and Cleaning \n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import regex\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "#Visualizations\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import pyLDAvis.gensim\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py \n",
    "import chart_studio.tools as tls\n",
    "\n",
    "#Natural Language Processing (NLP)\n",
    "import spacy\n",
    "import gensim\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS as SW\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def give_emoji_free_text(text):\n",
    "#     \"\"\"\n",
    "#     Removes emoji's from tweets\n",
    "#     Accepts:\n",
    "#         Text (tweets)\n",
    "#     Returns:\n",
    "#         Text (emoji free tweets)\n",
    "#     \"\"\"\n",
    "#     emoji_list = [c for c in text if c in emoji.UNICODE_EMOJI]\n",
    "#     clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "#     return clean_text\n",
    "\n",
    "# def url_free_text(text):\n",
    "#     '''\n",
    "#     Cleans text from urls\n",
    "#     '''\n",
    "#     text = re.sub(r'http\\S+', '', text)\n",
    "#     return text\n",
    "\n",
    "# # Apply the function above and get tweets free of emoji's\n",
    "# call_emoji_free = lambda x: give_emoji_free_text(x)\n",
    "\n",
    "# # Apply `call_emoji_free` which calls the function to remove all emoji's\n",
    "# df['emoji_free_tweets'] = df['original_tweets'].apply(call_emoji_free)\n",
    "\n",
    "# #Create a new column with url free tweets\n",
    "# df['url_free_tweets'] = df['emoji_free_tweets'].apply(url_free_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Tokenization is always the first step before we can do any text data processing. What this means is that spaCy will segment sentences into words, punctuations, symbols and others by applying specific rules to each language. Spacy is a pre-trained natural language processing model capable of figuring out the relationship between words. You can learn more about Spacy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN tweets\n",
    "tweets_df_sent.dropna(subset = ['clean_text', 'full_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "\n",
    "# Custom stopwords\n",
    "custom_stopwords = ['hi','\\n','\\n\\n', '&amp;', ' ', '.', '-', 'got', \"it's\", 'it’s', \"i'm\", 'i’m', 'im', 'want', 'like', '$', '@']\n",
    "\n",
    "# Customize stop words by adding to the default list\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union(custom_stopwords)\n",
    "\n",
    "# ALL_STOP_WORDS = spacy + gensim + wordcloud\n",
    "ALL_STOP_WORDS = STOP_WORDS.union(SW).union(stopwords)\n",
    "\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(tweets_df_sent['clean_text'], batch_size=500):\n",
    "    doc_tokens = []    \n",
    "    for token in doc: \n",
    "        if token.text.lower() not in STOP_WORDS:\n",
    "            doc_tokens.append(token.text.lower())   \n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "# Makes tokens column\n",
    "tweets_df_sent['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmetization\n",
    "Lemmatization is a process where we convert words to its root word. For example: ‘Studying’ becomes ‘Study’, ‘Meeting becomes ‘Meet’, ‘Better’ and ‘Best’ become ‘Good’.The advantage of this is, we get to reduce the total number of unique words in the dictionary. As a result, the number of columns in the document-word matrix will be denser with lesser columns. The ultimate goal of lemmatization is to help the LDA model to produce better topics in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tokens a string again\n",
    "tweets_df_sent['tokens_back_to_text'] = [' '.join(map(str, l)) for l in tweets_df_sent['tokens']]\n",
    "\n",
    "def get_lemmas(text):\n",
    "    '''Used to lemmatize the processed tweets'''\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_ != 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas\n",
    "\n",
    "tweets_df_sent['lemmas'] = tweets_df_sent['tokens_back_to_text'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lemmas a string again\n",
    "tweets_df_sent['lemmas_back_to_text'] = [' '.join(map(str, l)) for l in tweets_df_sent['lemmas']]\n",
    "\n",
    "# Tokenizer function\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Parses a string into a list of semantic units (words)\n",
    "    Args:\n",
    "        text (str): The string that the function will tokenize.\n",
    "    Returns:\n",
    "        list: tokens parsed out\n",
    "    \"\"\"\n",
    "    # Removing url's\n",
    "    pattern = r\"http\\S+\"\n",
    "    \n",
    "    tokens = re.sub(pattern, \"\", text) # https://www.youtube.com/watch?v=O2onA4r5UaY\n",
    "    tokens = re.sub('[^a-zA-Z 0-9]', '', text)\n",
    "    tokens = re.sub('[%s]' % re.escape(string.punctuation), '', text) # Remove punctuation\n",
    "    tokens = re.sub('\\w*\\d\\w*', '', text) # Remove words containing numbers\n",
    "    tokens = re.sub('@*!*\\$*', '', text) # Remove @ ! $\n",
    "    tokens = tokens.strip(',') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('?') # TESTING THIS LINE\n",
    "    tokens = tokens.strip('!') # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\"'\") # TESTING THIS LINE\n",
    "    tokens = tokens.strip(\".\") # TESTING THIS LINE\n",
    "\n",
    "    tokens = tokens.lower().split() # Make text lowercase and split it\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply tokenizer\n",
    "tweets_df_sent['lemma_tokens'] = tweets_df_sent['lemmas_back_to_text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_sent.to_csv('../2Mtweets_sentiment_lt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('100000_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream a user timeline\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    " \n",
    "consumer_key = 'BrfwPUQwUrXrTI8PsbpQLd8cY'\n",
    "consumer_secret = '71FyuTaHH6qoPZdilbXONYRn9mURCSJLGgJYpFzdscmzCrGY9N'\n",
    "access_token = '306806203-TCvwu2u4fKPEPJE6OQnc1s7VuIGNYb3cbDPK9h49'\n",
    "access_secret = 'b1COlCPF0eUIb74vsw01lV0maoy28nxYlKvt5W4lL1phz'\n",
    " \n",
    "@classmethod\n",
    "def parse(cls, api, raw):\n",
    "    status = cls.first_parse(api, raw)\n",
    "    setattr(status, 'json', json.dumps(raw))\n",
    "    return status\n",
    " \n",
    "# Status() is the data model for a tweet\n",
    "tweepy.models.Status.first_parse = tweepy.models.Status.parse\n",
    "tweepy.models.Status.parse = parse\n",
    "# User() is the data model for a user profile\n",
    "tweepy.models.User.first_parse = tweepy.models.User.parse\n",
    "tweepy.models.User.parse = parse\n",
    "# You need to do it for all the models you need\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'greg_doucette'\n",
    "tweets = []\n",
    "for tweet in tweepy.Cursor(api.user_timeline, id=username, tweet_mode='extended').items():\n",
    "    tweets += tweet.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(5000)\n",
    "username = 'greg_doucette'\n",
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []  \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name,count=200, tweet_mode='extended')\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(f\"getting tweets before {oldest}\")\n",
    "        \n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest, tweet_mode='extended')\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "        \n",
    "    return alltweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_all_tweets(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3203"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tweets to file\n",
    "tweet_files = []\n",
    "for status in tweets:\n",
    "    tweet_files.append(status._json)\n",
    "# write files\n",
    "with open(username + \"3200_extended_tweets.json\", 'w') as f:\n",
    "    json.dump(tweet_files, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for line in open('greg_doucette3200_extended_tweets.json', 'r'):\n",
    "    tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_urls = []\n",
    "text = []\n",
    "created_at = []\n",
    "location = []\n",
    "for tweet in range(len(tweet_files)-1):\n",
    "    if 'extended_entities' in tweet_files[tweet].keys():\n",
    "        if tweet_files[tweet]['extended_entities']['media'][0]['type'] == 'video':\n",
    "#         if tweet_files[tweet]['in_reply_to_status_id_str'] == '1268773302421651462':\n",
    "#         if 'media' in tweet_files[tweet]['extended_entities'].keys():\n",
    "            try:\n",
    "                video_urls.append(tweet_files[tweet]['extended_entities']['media'][0]['video_info']['variants'][1]['url'])\n",
    "            except KeyError:\n",
    "                video_urls.append(None)\n",
    "            text.append(tweet_files[tweet]['full_text'])\n",
    "            created_at.append(tweet_files[tweet]['created_at'])\n",
    "            location.append(tweet_files[tweet]['full_text'].split(\":\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\\ufe0f\\u20e34\\ufe0f\\u20e36\\ufe0f\\u20e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# threads: 1268773302421651462, 1267974239237345280\n",
    "video_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Y'all remember 1️⃣4️⃣6️⃣ out of Richmond VA?\\n\\nWhere police opened fire on peaceful protestors without provocation?… https://t.co/mON0HbyxSd\""
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_files[9]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_files[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 25757991 / 25757991"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0BaH6MSWxSZavX2o.mp4'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "wget.download('https://video.twimg.com/ext_tw_video/1268692323690373120/pu/vid/592x1280/0BaH6MSWxSZavX2o.mp4?tag=10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
